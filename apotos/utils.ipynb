{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from typing import Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats.mstats import gmean\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "ON_KAGGLE: bool = 'KAGGLE_WORKING_DIR' in os.environ\n",
    "#ON_KAGGLE = True\n",
    "\n",
    "def gmean_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.groupby(level=0).agg(lambda x: gmean(list(x)))\n",
    "\n",
    "\n",
    "def mean_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    return df.groupby(level=0).mean()\n",
    "\n",
    "\n",
    "def load_model(model: nn.Module, path: Path) -> Dict:\n",
    "    state = torch.load(str(path))\n",
    "    model.load_state_dict(state['model'])\n",
    "    print('Loaded model from epoch {epoch}, step {step:,}'.format(**state))\n",
    "    return state\n",
    "\n",
    "\n",
    "class ThreadingDataLoader(DataLoader):\n",
    "    def __iter__(self):\n",
    "        sample_iter = iter(self.batch_sampler)\n",
    "        if self.num_workers == 0:\n",
    "            for indices in sample_iter:\n",
    "                yield self.collate_fn([self._get_item(i) for i in indices])\n",
    "        else:\n",
    "            prefetch = 1\n",
    "            with ThreadPool(processes=self.num_workers) as pool:\n",
    "                futures = []\n",
    "                for indices in sample_iter:\n",
    "                    futures.append([pool.apply_async(self._get_item, args=(i,))\n",
    "                                    for i in indices])\n",
    "                    if len(futures) > prefetch:\n",
    "                        yield self.collate_fn([f.get() for f in futures.pop(0)])\n",
    "                    # items = pool.map(lambda i: self.dataset[i], indices)\n",
    "                    # yield self.collate_fn(items)\n",
    "                for batch_futures in futures:\n",
    "                    yield self.collate_fn([f.get() for f in batch_futures])\n",
    "\n",
    "    def _get_item(self, i):\n",
    "        return self.dataset[i]\n",
    "\n",
    "\n",
    "def write_event(log, step: int, **data):\n",
    "    data['step'] = step\n",
    "    data['dt'] = datetime.now().isoformat()\n",
    "    log.write(json.dumps(data, sort_keys=True))\n",
    "    log.write('\\n')\n",
    "    log.flush()\n",
    "\n",
    "\n",
    "def plot(*args, ymin=None, ymax=None, xmin=None, xmax=None, params=False,\n",
    "         max_points=200, legend=True, title=None,\n",
    "         print_keys=False, print_paths=False, plt=None, newfigure=True,\n",
    "         x_scale=1):\n",
    "    \"\"\"\n",
    "    Use in the notebook like this::\n",
    "\n",
    "        %matplotlib inline\n",
    "        from imet.utils import plot\n",
    "        plot('./runs/oc2', './runs/oc1', 'loss', 'valid_loss')\n",
    "\n",
    "    \"\"\"\n",
    "    import json_lines  # no available on Kaggle\n",
    "\n",
    "    if plt is None:\n",
    "        from matplotlib import pyplot as plt\n",
    "    paths, keys = [], []\n",
    "    for x in args:\n",
    "        if x.startswith('.') or '/' in x:\n",
    "            if '*' in x:\n",
    "                paths.extend(glob.glob(x))\n",
    "            else:\n",
    "                paths.append(x)\n",
    "        else:\n",
    "            keys.append(x)\n",
    "    if print_paths:\n",
    "        print('Found paths: {}'.format(' '.join(sorted(paths))))\n",
    "    if newfigure:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "    keys = keys or ['loss', 'valid_loss']\n",
    "\n",
    "    ylim_kw = {}\n",
    "    if ymin is not None:\n",
    "        ylim_kw['bottom'] = ymin\n",
    "    if ymax is not None:\n",
    "        ylim_kw['top'] = ymax\n",
    "    if ylim_kw:\n",
    "        plt.ylim(**ylim_kw)\n",
    "\n",
    "    xlim_kw = {}\n",
    "    if xmin is not None:\n",
    "        xlim_kw['left'] = xmin\n",
    "    if xmax is not None:\n",
    "        xlim_kw['right'] = xmax\n",
    "    if xlim_kw:\n",
    "        plt.xlim(**xlim_kw)\n",
    "    all_keys = set()\n",
    "    for path in sorted(paths):\n",
    "        path = Path(path)\n",
    "        with json_lines.open(path / 'train.log', broken=True) as f:\n",
    "            events = list(f)\n",
    "        all_keys.update(k for e in events for k in e)\n",
    "        for key in sorted(keys):\n",
    "            xs, ys, ys_err = [], [], []\n",
    "            for e in events:\n",
    "                if key in e:\n",
    "                    xs.append(e['step'] * x_scale)\n",
    "                    ys.append(e[key])\n",
    "                    std_key = key + '_std'\n",
    "                    if std_key in e:\n",
    "                        ys_err.append(e[std_key])\n",
    "            if xs:\n",
    "                if np.isnan(ys).any():\n",
    "                    print('Warning: NaN {} for {}'.format(key, path))\n",
    "                if len(xs) > 2 * max_points:\n",
    "                    indices = (np.arange(0, len(xs) - 1, len(xs) / max_points)\n",
    "                               .astype(np.int32))\n",
    "                    xs = np.array(xs)[indices[1:]]\n",
    "                    ys = _smooth(ys, indices)\n",
    "                    if ys_err:\n",
    "                        ys_err = _smooth(ys_err, indices)\n",
    "                label = '{}: {}'.format(path, key)\n",
    "                if label.startswith('_'):\n",
    "                    label = ' ' + label\n",
    "                if ys_err:\n",
    "                    ys_err = 1.96 * np.array(ys_err)\n",
    "                    plt.errorbar(xs, ys, yerr=ys_err,\n",
    "                                 fmt='-o', capsize=5, capthick=2,\n",
    "                                 label=label)\n",
    "                else:\n",
    "                    plt.plot(xs, ys, label=label)\n",
    "                plt.legend()\n",
    "    if newfigure:\n",
    "        plt.grid()\n",
    "    if legend:\n",
    "        plt.legend()\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    if print_keys:\n",
    "        print('Found keys: {}'\n",
    "              .format(', '.join(sorted(all_keys - {'step', 'dt'}))))\n",
    "\n",
    "\n",
    "def _smooth(ys, indices):\n",
    "    return [np.mean(ys[idx: indices[i + 1]])\n",
    "            for i, idx in enumerate(indices[:-1])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
