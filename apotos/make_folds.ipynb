{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME  : 以下の関数は定義されたファイルの形式に依存するので、utilsに記載できない。\n",
    "def is_env_notebook():\n",
    "    \"\"\"Determine wheather is the environment Jupyter Notebook\"\"\"\n",
    "    if 'get_ipython' not in globals():\n",
    "        # Python shell\n",
    "        return False\n",
    "    env_name = get_ipython().__class__.__name__\n",
    "    if env_name == 'TerminalInteractiveShell':\n",
    "        # IPython shell\n",
    "        return False\n",
    "    # Jupyter Notebook\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append('.')\n",
    "\n",
    "import argparse\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from IPython.core.debugger import Pdb\n",
    "\n",
    "ON_KAGGLE: bool = 'KAGGLE_WORKING_DIR' in os.environ\n",
    "\n",
    "if ON_KAGGLE:\n",
    "    from .dataset import DATA_ROOT,EXTERNAL_ROOT\n",
    "else:\n",
    "    from dataset import DATA_ROOT,EXTERNAL_ROOT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_foldsはマルチラベル用になってる。\n",
    "def make_folds_for_multilabel(n_folds: int) -> pd.DataFrame:\n",
    "    df = pd.read_csv(DATA_ROOT / 'train.csv')\n",
    "    cls_counts = Counter(cls for classes in df['attribute_ids'].str.split()\n",
    "                         for cls in classes)\n",
    "    fold_cls_counts = defaultdict(int)\n",
    "    folds = [-1] * len(df)\n",
    "    for item in tqdm.tqdm(df.sample(frac=1, random_state=42).itertuples(),\n",
    "                          total=len(df)):\n",
    "        cls = min(item.attribute_ids.split(), key=lambda cls: cls_counts[cls])\n",
    "        fold_counts = [(f, fold_cls_counts[f, cls]) for f in range(n_folds)]\n",
    "        min_count = min([count for _, count in fold_counts])\n",
    "        random.seed(item.Index)\n",
    "        fold = random.choice([f for f, count in fold_counts\n",
    "                              if count == min_count])\n",
    "        folds[item.Index] = fold\n",
    "        for cls in item.attribute_ids.split():\n",
    "            fold_cls_counts[fold, cls] += 1\n",
    "    df['fold'] = folds\n",
    "    return df\n",
    "\n",
    "def make_folds(n_folds:int,seed:int=42,rmdup:bool=True) -> pd.DataFrame:\n",
    "    if rmdup:\n",
    "       # 重複除去について\n",
    "        strmd5 = (pd.read_csv(\"../input/strmd5/strMd5.csv\").\n",
    "                 query(\"strMd5_nunique == 1\")) # ラベルの不安な検体は除外 2検体はある\n",
    "\n",
    "        # 学習データとテストデータのフラグを作成\n",
    "        strmd5[\"dataset\"] = [\"train\" if diagnosis >= 0 else \"test\" for diagnosis in strmd5[\"diagnosis\"]]\n",
    "        # テストデータ\n",
    "        strmd5[\"strMd5_test_count\"] = strmd5.strMd5_count - strmd5.strMd5_train_count\n",
    "\n",
    "        # 学習データの中でテストデータに存在するデータをリークと定義。\n",
    "        strmd5[\"leak\"] = [\"leak\" if tup[\"dataset\"] == \"train\" and tup[\"strMd5_test_count\"] >=1 else \"not leak\" \n",
    "                          for i,tup in strmd5.loc[:,[\"strMd5_test_count\",\"dataset\"]].iterrows()]\n",
    "\n",
    "        # strmd5 train\n",
    "        strmd5_train = (strmd5.\n",
    "                        query(\"dataset == 'train' and leak == 'not leak'\"))\n",
    "\n",
    "        strmd5_train_nodup = (strmd5_train.\n",
    "                             drop_duplicates(subset=[\"strMd5\",\"diagnosis\"],keep=False).\n",
    "                             reset_index(drop=True)\n",
    "                             )\n",
    "\n",
    "        strmd5_train_dup = strmd5_train.loc[strmd5_train.duplicated(subset=[\"strMd5\",\"diagnosis\"]),[\"id_code\",\"diagnosis\"]]\n",
    "\n",
    "        strmd5_train[\"diagnosis\"] = strmd5_train[\"diagnosis\"].astype(\"int64\")\n",
    "\n",
    "        # strmd5 train leak\n",
    "        strmd5_train_leak = (strmd5.\n",
    "                             query(\"dataset == 'train' and leak == 'leak'\").\n",
    "                             drop_duplicates(subset=[\"strMd5\",\"diagnosis\"]).\n",
    "                             reset_index(drop=True).\n",
    "                             loc[:,[\"id_code\",\"diagnosis\"]]\n",
    "                            )\n",
    "        \n",
    "        strmd5_train_dup[\"fold\"] = -1\n",
    "        strmd5_train_leak[\"fold\"] = -1\n",
    "        \n",
    "        df = strmd5_train_nodup.loc[:,[\"id_code\",\"diagnosis\"]]\n",
    "        \n",
    "    else:\n",
    "        df = pd.read_csv(DATA_ROOT / 'train.csv')\n",
    "    \n",
    " #   Pdb().set_trace()\n",
    "    cls_counts = Counter(cls for cls in df[\"diagnosis\"])\n",
    "    \n",
    "    fold_cls_counts = defaultdict(int)\n",
    "    folds = [-1] * len(df)\n",
    "    \n",
    "    for item in tqdm.tqdm(df.sample(frac=1, random_state=seed).itertuples(),\n",
    "                      total=len(df)):\n",
    "     #   Pdb().set_trace()\n",
    "        cls = item.diagnosis\n",
    "        fold_counts = [(f, fold_cls_counts[f, cls]) for f in range(n_folds)]\n",
    "        min_count = min([count for _, count in fold_counts])\n",
    "        random.seed(item.Index)\n",
    "        fold = random.choice([f for f, count in fold_counts\n",
    "                              if count == min_count])\n",
    "        folds[item.Index] = fold\n",
    "        #for cls in item.diagnosis:\n",
    "        fold_cls_counts[fold, cls] += 1\n",
    "        \n",
    "#   from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "    df['fold'] = folds\n",
    "    \n",
    "    if rmdup:\n",
    "        df = pd.concat([df,strmd5_train_leak,strmd5_train_dup])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def external_data() -> pd.DataFrame:\n",
    "    df = pd.read_csv(EXTERNAL_ROOT / \"trainLabels.csv\")\\\n",
    "            .rename(columns = {\"id_code\":\"image\",\"diagnosis\":\"level\"})\n",
    "    \n",
    "    df[\"fold\"] = 99\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      image  level  fold\n",
      "0   10_left      0    99\n",
      "1  10_right      0    99\n",
      "2   13_left      0    99\n",
      "3  13_right      0    99\n",
      "4   15_left      1    99\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pass\n",
    "    # df = external_data()\n",
    "   # print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "100%|██████████| 3277/3277 [00:00<00:00, 80902.77it/s]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--n-folds', type=int, default=5)\n",
    "    \n",
    "    ## jupyter-notebookかどうか判定\n",
    "    if is_env_notebook():\n",
    "        args = parser.parse_args(args=[])\n",
    "    else:\n",
    "        args = parser.parse_args()\n",
    "        \n",
    "    df = make_folds(n_folds=args.n_folds)\n",
    "    df.to_csv('folds.csv', index=None)\n",
    "   # from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
